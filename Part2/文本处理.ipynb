{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba.analyse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\百度停用词表.txt\"\n",
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\哈工大停用词表.txt\"\n",
    "stop_words_path = \"/home/yang/PycharmProjects/NLP_projects/resources/stopwords-master/哈工大停用词表.txt\"\n",
    "stop_words = pd.read_csv(stop_words_path,index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stop_words = stop_words['stopword'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\面试-训练测试集.xlsx\"\n",
    "data_path = \"/home/yang/PycharmProjects/NLP_projects/resources/面试-训练测试集.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# title_data = data['title']\n",
    "# content_data = data['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.定义文本预处理函数\n",
    "\n",
    "* 去停用词，分词\n",
    "* 参数 titles, contents, sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_percents(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        right = right.split('%')[0]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "            \n",
    "    elif s.count(\".\") != 1:\n",
    "        left = s.split('%')[0]\n",
    "        if left.isdigit():\n",
    "            return True\n",
    "               \n",
    "    return False\n",
    "\n",
    "\n",
    "def preprocess_text(title, content, sentences, label):\n",
    "    \n",
    "#     处理标题\n",
    "    title_info = jieba.lcut(title)\n",
    "\n",
    "    title_info = [v for v in title_info if not str(v).isdigit()]#去数字\n",
    "    title_info = list(filter(lambda x:x.strip(), title_info))   #去左右空格\n",
    "    \n",
    "\n",
    "    title_info = list(filter(lambda x:len(x)>1, title_info)) #长度为1的字符\n",
    "    title_info = list(filter(lambda x:x not in stop_words, title_info)) #去掉停用词\n",
    "    \n",
    "#     print(\"标题信息是：\" ,title_info)\n",
    "#     sentences.append(segs)\n",
    "#     sentences.append((\" \".join(segs), label))# 打标签\n",
    "            \n",
    "#     处理文章内容        \n",
    "    segs=jieba.lcut(content)\n",
    "    segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "    segs = [v for v in segs if not is_float(v)] #去小数\n",
    "    segs = [v for v in segs if not is_percents(v)] #去百分数\n",
    "\n",
    "    segs = list(filter(lambda x:x.strip(), segs))   #去左右空格\n",
    "    segs = list(filter(lambda x:len(x)>1, segs)) #长度为1的字符\n",
    "    segs = list(filter(lambda x:x not in stop_words, segs)) #去掉停用词\n",
    "    \n",
    "#     print(\"内容信息是:\", segs)\n",
    "    segs = title_info + segs\n",
    "    sentences.append((\" \".join(segs), label))# 打标签\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "#     print(row['title'], row['content'])\n",
    "    title = row['title']\n",
    "    content = row['content']\n",
    "    label = row['label']\n",
    "    preprocess_text(title, content, sentences, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "文章分词: 赵东 交易所 周线 放量 现在 反弹 不是 牛市 创始人 赵东 发微 博称 激动 交易所 周线 放量 现在 反弹 不是 牛市 牛会来 不是 现在 耐心\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 小幅 回调 美元 附近 宽幅 震荡 昨日 高涨 美元 目前 小幅 回调 主流 多数 小幅 回调 美元 24h 跌幅 全球 数字 货币 市场 总价值 亿美元 24h 成交量 亿美元 全球 均价 美元 三大 主流 交易所 现报 美元 现报 美元 币安现 美元 主流 数字 货币 表现 如下 暂报 美元 XRP 暂报 美元 BCH 暂报 美元 LTC 暂报 美元 ETC 暂报 美元 EOS 暂报 美元 小时 市值 排名 前百 币种 涨幅 前三为 NULS NANO XTZ 跌幅 前三为 FT WAX PAI 概念 板块 涨幅 前三为 DAG 技术 合约 工具 跨链 跌幅 前三为 人工智能 身份验证 联网 以上 涨跌幅 24h 计算\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 短时 跌破 美元 刚刚 快速 下跌 短时 跌破 美元 最低 跌至 美元 略有 回升 现报 美元 今日 跌幅 提醒\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 过去 小时 推特 讨论 排名 第一 XRP 排名 三位 数据 显示 过去 小时 推特 讨论 排行 讨论 排名 第一 排名 第二位 XRP 排名 第三位 讨论 排名 四至 十位 分别 LTC BAT ADA ATT TRX XVG BNB\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 分析 美元 均线 支撑 有效 分析 未来 几天 可能 回落 美元 第一季度 引领 市场 走高 LTC 显示 疲软 迹象 中旬 月底 LTC 几乎 走势 相同 多头 空头 比率 以来 首次 跌至 以下 表明 看跌 情绪 日益加剧 价格 回调 看起来 可能 价格 借助 上升 移动 平均线 目前 美元 反弹 下跌 美元 情况 将会 减弱\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 分析 期货 多空 实力 反转 市场 情绪 逐渐 冷静 数据分析 显示 截止 点整 价格 USDT 收益 回报率 ROI 环比 昨日 跌幅 RSI 指数 处于 正常 区间 期货 方面 Bitfinex BitMEX 总多 单量 总空 单量 相较 此前 情况 市场 看好 情绪 已然 冷静 空头 势力 逐渐 攀升\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 过去 小时 推特 讨论 排名 第一 XRP 排名 三位 数据 显示 过去 小时 推特 讨论 排行 讨论 排名 第一 排名 第二位 XRP 排名 第三位 讨论 排名 四至 十位 分别 LTC BAT ADA ATT TRX XVG BNB\n",
      "文章标签： 中性\n",
      "-------\n",
      "文章分词: 链上 出现 价值 万美元 大额 转账 监测 北京 链上 出现 大额 转账 钱包 地址 地址 转账 价值 万美元\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: XRP 主流 普跌 XRP 主流 币种 短时 持续 下跌 现报 美元 24h 跌幅 现报 美元 24h 跌幅 XRP 现报 美元 24h 跌幅 主流 普跌 提醒\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 短时 再次 跌破 美元 短时 持续 下跌 跌破 美元 现报 美元 跌幅 提醒\n",
      "文章标签： 负面\n"
     ]
    }
   ],
   "source": [
    "# random.shuffle(sentences)\n",
    "for sentence in sentences[:10]:\n",
    "    print(\"-------\")\n",
    "    print(\"文章分词:\", sentence[0])\n",
    "    print(\"文章标签：\", sentence[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 抽取词向量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 抽取特征， 定义词袋模型\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    ngram_range=(1,4),  # use ngrams of size 1 and 2\n",
    "    max_features=1000,  # keep the most common 1000 ngrams\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 语料切分\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.35, random_state=1256)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=4000, min_df=1,\n",
       "                ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 把训练数据转为词袋模型\n",
    "vec.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.算法建模与模型训练 （贝叶斯）\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# classifier = MultinomialNB()\n",
    "# classifier.fit(vec.transform(x_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 评估结果 AUC值\n",
    "# print(classifier.score(vec.transform(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM模型评价，训练集正确率 1.0\n",
      "SVM模型评价，测试集正确率 0.8342857142857143\n"
     ]
    }
   ],
   "source": [
    "# 4.算法建模与模型训练 （SVM）\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# svm = SVC(kernel='linear')\n",
    "svm = SVC(C=1.0,kernel='linear',gamma='auto')\n",
    "svm.fit(vec.transform(x_train), y_train)\n",
    "\n",
    "print(\"SVM模型评价，训练集正确率\",svm.score(vec.transform(x_train), y_train))\n",
    "print(\"SVM模型评价，测试集正确率\",svm.score(vec.transform(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目前准确率在测试集上为80%左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经网络模型评价，训练集正确率 1.0\n",
      "神经网络模型评价, 测试集正确率: 0.8457142857142858\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neural_network as sk_nn\n",
    "model = sk_nn.MLPClassifier(activation='logistic',solver='lbfgs',alpha=0.0001,learning_rate='adaptive',learning_rate_init=0.001,max_iter=2000)\n",
    "model.fit(vec.transform(x_train),y_train)\n",
    "\n",
    "print(\"神经网络模型评价，训练集正确率\", model.score(vec.transform(x_train), y_train))\n",
    "\n",
    "acc=model.score(vec.transform(x_test),y_test) #根据给定数据与标签返回正确率的均值\n",
    "print('神经网络模型评价, 测试集正确率:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
