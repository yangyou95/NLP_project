{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba.analyse\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\百度停用词表.txt\"\n",
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\哈工大停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_projects/resources/stopwords-master/哈工大停用词表.txt\"\n",
    "stop_words_path = \"/home/yang/PycharmProjects/NLP_projects/resources/stopwords-master/中文停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_projects/resources/stopwords-master/modified_stopwords.txt\"\n",
    "\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/中文停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/百度停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/modified_stopwords.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/四川大学机器智能实验室停用词库.txt\"\n",
    "\n",
    "stop_words = pd.read_csv(stop_words_path,index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stop_words = stop_words['stopword'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\面试-训练测试集.xlsx\"\n",
    "data_path = \"/home/yang/PycharmProjects/NLP_projects/resources/面试-训练测试集.xlsx\"\n",
    "predict_data_path = \"/home/yang/PycharmProjects/NLP_projects/resources/面试-待预测集.xlsx\"\n",
    "# data_path = \"/home/yang/PycharmProjects/NLP_project/resources/面试-训练测试集.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "predict_data = pd.read_excel(predict_data_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.定义文本预处理函数\n",
    "\n",
    "* 去无关字符，去停用词，分词\n",
    "* 参数 titles, contents, sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_percents(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        right = right.split('%')[0]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "            \n",
    "    elif s.count(\".\") != 1:\n",
    "        left = s.split('%')[0]\n",
    "        if left.isdigit():\n",
    "            return True\n",
    "               \n",
    "    return False\n",
    "\n",
    "def is_all_chinese(strs):\n",
    "    for _char in strs:\n",
    "        if not '\\u4e00' <= _char <= '\\u9fa5':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def preprocess_text(title, content, sentences, label):\n",
    "    \n",
    "#     处理标题\n",
    "    title_info = jieba.lcut(title)\n",
    "\n",
    "    title_info = [v for v in title_info if not str(v).isdigit()]#去数字\n",
    "    title_info = list(filter(lambda x:x.strip(), title_info))   #去左右空格\n",
    "    \n",
    "\n",
    "    title_info = list(filter(lambda x:len(x)>1, title_info)) #长度为1的字符\n",
    "    title_info = list(filter(lambda x:x not in stop_words, title_info)) #去掉停用词\n",
    "            \n",
    "#     处理文章内容        \n",
    "    segs=jieba.lcut(content)\n",
    "    segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "    segs = [v for v in segs if not is_float(v)] #去小数\n",
    "    segs = [v for v in segs if not is_percents(v)] #去百分数\n",
    "\n",
    "    segs = list(filter(lambda x:x.strip(), segs))   #去左右空格\n",
    "    segs = list(filter(lambda x:len(x)>1, segs)) #长度为1的字符\n",
    "    segs = list(filter(lambda x:x not in stop_words, segs)) #去掉停用词\n",
    "    \n",
    "    \n",
    "#     print(\"内容信息是:\", segs)\n",
    "    segs = title_info + segs  \n",
    "    segs = [v for v in segs if is_all_chinese(str(v))] #去字母词\n",
    "    \n",
    "    sentences.append((\" \".join(segs), label))# 打标签"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "#     print(row['title'], row['content'])\n",
    "    title = row['title']\n",
    "    content = row['content']\n",
    "    label = row['label']\n",
    "    preprocess_text(title, content, sentences, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pos_sentences = []\n",
    "neg_sentences = []\n",
    "neu_sentences = []\n",
    "\n",
    "for seg in sentences:\n",
    "    if seg[1] == \"正面\":\n",
    "        pos_sentences.append(seg)\n",
    "    elif seg[1] == \"负面\":\n",
    "        neg_sentences.append(seg)\n",
    "    elif seg[1] == \"中性\":\n",
    "        neu_sentences.append(seg)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 抽取词向量特征\n",
    "\n",
    "* 测试了两种提取方法，CountVectorizer词频提取和TfidfVectorizer的td-idf特性提取\n",
    "* CountVectorizer提取词频特征后，在训练集上有明显过拟合现象\n",
    "* Tf-idf模型能更有效避免噪声词的干扰，在测试集上表现更好，这里用Tf-idf来构建词袋模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 抽取特征， 定义词袋模型\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# vec = CountVectorizer(\n",
    "#     analyzer='word', # tokenise by character ngrams\n",
    "#     ngram_range=(1,2),  # use ngrams of size 1 and 2\n",
    "#     max_features=1000,  # keep the most common 1000 ngrams\n",
    "# )\n",
    "\n",
    "vec = TfidfVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    ngram_range=(1,2),  # use ngrams of size 1 and 2\n",
    "    max_features= None,  # keep the most common 1000 ngrams\n",
    "    use_idf=1,smooth_idf=1,sublinear_tf=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187\n",
      "112\n"
     ]
    }
   ],
   "source": [
    "# 2. 语料切分, 分出测试集用于验证\n",
    "# 因为负面，中性的数据占比过少，需手动调整在训练集中的比例，防止这两类训练过少\n",
    "from sklearn.model_selection import train_test_split\n",
    "pos_x, pos_y = zip(*pos_sentences)\n",
    "neg_x, neg_y = zip(*neg_sentences)\n",
    "neu_x, neu_y = zip(*neu_sentences)\n",
    "x_train_pos, x_test_pos, y_train_pos, y_test_pos = train_test_split(pos_x, pos_y,test_size=0.48, random_state=1)\n",
    "x_train_neg, x_test_neg, y_train_neg, y_test_neg = train_test_split(neg_x, neg_y,test_size=0.08, random_state=2)\n",
    "x_train_neu, x_test_neu, y_train_neu, y_test_neu = train_test_split(neu_x, neu_y,test_size=0.1, random_state=3)\n",
    "\n",
    "x_train = x_train_pos + x_train_neg + x_train_neu\n",
    "x_test = x_test_pos + x_test_neg + x_test_neu\n",
    "y_train = y_train_pos + y_train_neg + y_train_neu\n",
    "y_test = y_test_pos + y_test_neg + y_test_neu\n",
    "\n",
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(len(x_train)):\n",
    "    train_data_pair = [x_train[i],y_train[i]]\n",
    "    train_data.append(train_data_pair)\n",
    "    \n",
    "for i in range(len(x_test)):\n",
    "    test_data_pair = [x_test[i],y_test[i]]\n",
    "    test_data.append(test_data_pair)\n",
    "\n",
    "# 打乱数据顺序\n",
    "random.shuffle(train_data)\n",
    "random.shuffle(test_data)\n",
    "\n",
    "x_train, y_train = zip(*train_data)\n",
    "x_test, y_test = zip(*test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 把训练数据转为词袋模型\n",
    "vec.fit(x_train)\n",
    "x_train_data = vec.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项贝叶斯模型评价，训练集正确率: 0.89171974522293\n"
     ]
    }
   ],
   "source": [
    "# 4.算法建模与模型训练 （贝叶斯）\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train_data, y_train)\n",
    "# 5. 评估结果 AUC值\n",
    "print(\"多项贝叶斯模型评价，训练集正确率:\",classifier.score(vec.transform(x_train), y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM模型评价，训练集正确率 0.964968152866242\n"
     ]
    }
   ],
   "source": [
    "# 4.算法建模与模型训练 （SVM）\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# svm = SVC(kernel='linear')\n",
    "svm = SVC(C=1.0,kernel='linear',gamma='auto')\n",
    "svm.fit(x_train_data, y_train)\n",
    "\n",
    "print(\"SVM模型评价，训练集正确率\",svm.score(x_train_data, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经网络模型评价，训练集正确率 0.9904458598726115\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neural_network as sk_nn\n",
    "model = sk_nn.MLPClassifier(activation='tanh',solver='adam',alpha=0.0001,learning_rate='adaptive',learning_rate_init=0.01,max_iter=4000)\n",
    "model.fit(x_train_data,y_train)\n",
    "\n",
    "print(\"神经网络模型评价，训练集正确率\", model.score(x_train_data, y_train))\n",
    "\n",
    "acc=model.score(vec.transform(x_test),y_test) #根据给定数据与标签返回正确率的均值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.检验模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项贝叶斯模型评价，测试集正确率: 0.9081081081081082\n",
      "SVM模型评价，测试集正确率 0.8972972972972973\n",
      "神经网络模型评价, 测试集正确率: 0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "print(\"多项贝叶斯模型评价，测试集正确率:\",classifier.score(vec.transform(x_test), y_test))\n",
    "print(\"SVM模型评价，测试集正确率\",svm.score(vec.transform(x_test), y_test))\n",
    "print('神经网络模型评价, 测试集正确率:',acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目前准确率最高的模型在测试集上为90%左右, 保存所有训练的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "# 保存神经网络模型\n",
    "joblib.dump(model,'mlp.model') \n",
    "# 加载神经网络模型\n",
    "mlp_model=joblib.load('mlp.model')\n",
    "\n",
    "# 保存多项贝叶斯分类器的模型\n",
    "joblib.dump(classifier,'bayes.model')\n",
    "# 加载贝叶斯模型\n",
    "bayes_model = joblib.load('bayes.model')\n",
    "\n",
    "# 保存神经网络模型\n",
    "joblib.dump(svm,'svm.model') \n",
    "# 加载神经网络模型\n",
    "svm_model=joblib.load('svm.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 预测分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999\n"
     ]
    }
   ],
   "source": [
    "# 处理预测数据\n",
    "predict_data_sentences = []\n",
    "\n",
    "for index, row in predict_data.iterrows():\n",
    "#     print(row['title'], row['content'])\n",
    "    title = row['title']\n",
    "    content = row['content']\n",
    "    preprocess_text(title, content, predict_data_sentences, label= None)\n",
    "\n",
    "x, none_labels = zip(*predict_data_sentences)\n",
    "# vec.fit(x)\n",
    "x = vec.transform(x)\n",
    "\n",
    "# 应用模型进行预测\n",
    "result=mlp_model.predict(x)\n",
    "# result = bayes_model.predict(x)\n",
    "# result = svm_model.predict(x)\n",
    "print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1796\n",
      "[1796, 200, 3]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"10bf79e0163b436c96812f077cb8d44e\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_10bf79e0163b436c96812f077cb8d44e = echarts.init(\n",
       "                    document.getElementById('10bf79e0163b436c96812f077cb8d44e'), 'white', {renderer: 'canvas'});\n",
       "                var option_10bf79e0163b436c96812f077cb8d44e = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"pie\",\n",
       "            \"clockwise\": true,\n",
       "            \"data\": [\n",
       "                {\n",
       "                    \"name\": \"\\u6b63\\u9762\",\n",
       "                    \"value\": 1796\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u8d1f\\u9762\",\n",
       "                    \"value\": 200\n",
       "                },\n",
       "                {\n",
       "                    \"name\": \"\\u4e2d\\u6027\",\n",
       "                    \"value\": 3\n",
       "                }\n",
       "            ],\n",
       "            \"radius\": [\n",
       "                \"0%\",\n",
       "                \"75%\"\n",
       "            ],\n",
       "            \"center\": [\n",
       "                \"50%\",\n",
       "                \"50%\"\n",
       "            ],\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8,\n",
       "                \"formatter\": \"{b}: {c}\"\n",
       "            },\n",
       "            \"rippleEffect\": {\n",
       "                \"show\": true,\n",
       "                \"brushType\": \"stroke\",\n",
       "                \"scale\": 2.5,\n",
       "                \"period\": 4\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"\\u6b63\\u9762\",\n",
       "                \"\\u8d1f\\u9762\",\n",
       "                \"\\u4e2d\\u6027\"\n",
       "            ],\n",
       "            \"selected\": {},\n",
       "            \"show\": true,\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10,\n",
       "            \"itemWidth\": 25,\n",
       "            \"itemHeight\": 14\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0\n",
       "    },\n",
       "    \"title\": [\n",
       "        {\n",
       "            \"text\": \"\\u7c7b\\u522b\\u5206\\u6790\",\n",
       "            \"padding\": 5,\n",
       "            \"itemGap\": 10\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_10bf79e0163b436c96812f077cb8d44e.setOption(option_10bf79e0163b436c96812f077cb8d44e);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x7fc394dca320>"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.faker import Faker\n",
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Pie\n",
    "\n",
    "pos = 0\n",
    "neg = 0\n",
    "neu = 0\n",
    "\n",
    "for i in result:\n",
    "    if i == '正面':\n",
    "        pos = pos+ 1\n",
    "    elif i == '负面':\n",
    "        neg += 1\n",
    "    elif i == '中性':\n",
    "        neu += 1\n",
    "    else:\n",
    "        print('youyouyou')\n",
    "print(pos)        \n",
    "res = [pos, neg, neu] \n",
    "print(res)\n",
    "attr = ['正面','负面','中性']\n",
    "\n",
    "\n",
    "def pie_base() -> Pie:\n",
    "    c = (\n",
    "        Pie()\n",
    "        .add(\"\", [list(z) for z in zip(attr, res)])\n",
    "        .set_global_opts(title_opts=opts.TitleOpts(title=\"类别分析\"))\n",
    "        .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}\"))\n",
    "    )\n",
    "    return c\n",
    "\n",
    "\n",
    "pie= pie_base()\n",
    "pie.render_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 将预测的标签写入到csv文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0\n",
      "0     正面\n",
      "1     正面\n",
      "2     正面\n",
      "3     正面\n",
      "4     正面\n",
      "5     正面\n",
      "6     正面\n",
      "7     正面\n",
      "8     负面\n",
      "9     正面\n",
      "10    负面\n",
      "11    负面\n",
      "12    正面\n",
      "13    正面\n",
      "14    正面\n",
      "15    正面\n",
      "16    正面\n",
      "17    正面\n",
      "18    正面\n",
      "19    正面\n",
      "20    正面\n",
      "21    正面\n",
      "22    正面\n",
      "23    正面\n",
      "24    正面\n",
      "25    正面\n",
      "26    正面\n",
      "27    正面\n",
      "28    正面\n",
      "29    正面\n",
      "...   ..\n",
      "1969  正面\n",
      "1970  负面\n",
      "1971  正面\n",
      "1972  正面\n",
      "1973  正面\n",
      "1974  正面\n",
      "1975  正面\n",
      "1976  正面\n",
      "1977  正面\n",
      "1978  负面\n",
      "1979  正面\n",
      "1980  正面\n",
      "1981  正面\n",
      "1982  正面\n",
      "1983  正面\n",
      "1984  正面\n",
      "1985  正面\n",
      "1986  正面\n",
      "1987  正面\n",
      "1988  正面\n",
      "1989  正面\n",
      "1990  正面\n",
      "1991  正面\n",
      "1992  正面\n",
      "1993  正面\n",
      "1994  正面\n",
      "1995  正面\n",
      "1996  正面\n",
      "1997  正面\n",
      "1998  正面\n",
      "\n",
      "[1999 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import xlsxwriter as xlsw\n",
    "\n",
    "df_res = pd.DataFrame(result)\n",
    "print(df_res)\n",
    "writer = pd.ExcelWriter(predict_data_path, engine='xlsxwriter')\n",
    "df_res.to_excel(writer,startrow=2, startcol=6, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
