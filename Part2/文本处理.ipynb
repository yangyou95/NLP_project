{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba.analyse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\百度停用词表.txt\"\n",
    "stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\哈工大停用词表.txt\"\n",
    "stop_words = pd.read_csv(stop_words_path,index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stop_words = stop_words['stopword'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\面试-训练测试集.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# title_data = data['title']\n",
    "# content_data = data['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.定义文本预处理函数\n",
    "\n",
    "* 去停用词，分词\n",
    "* 参数 titles, contents, sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_percents(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        right = right.split('%')[0]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "            \n",
    "    elif s.count(\".\") != 1:\n",
    "        left = s.split('%')[0]\n",
    "        if left.isdigit():\n",
    "            return True\n",
    "               \n",
    "    return False\n",
    "\n",
    "\n",
    "def preprocess_text(title, content, sentences, label):\n",
    "    \n",
    "    # 处理标题\n",
    "#     segs=jieba.lcut(title)\n",
    "#     segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "# #     segs = list(filter(lambda x:x.strip(), segs))   #去左右空格\n",
    "#     segs = list(filter(lambda x:len(x)>1, segs)) #长度为1的字符\n",
    "# #     segs = list(filter(lambda x:x not in stop_words, segs)) #去掉停用词\n",
    "#     sentences.append(segs)\n",
    "\n",
    "            \n",
    "    # 处理文章内容        \n",
    "    segs=jieba.lcut(content)\n",
    "    segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "    segs = [v for v in segs if not is_float(v)] #去小数\n",
    "    segs = [v for v in segs if not is_percents(v)] #去百分数\n",
    "\n",
    "    segs = list(filter(lambda x:x.strip(), segs))   #去左右空格\n",
    "    segs = list(filter(lambda x:len(x)>1, segs)) #长度为1的字符\n",
    "    segs = list(filter(lambda x:x not in stop_words, segs)) #去掉停用词\n",
    "    sentences.append((\" \".join(segs), label))# 打标签\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "#     print(row['title'], row['content'])\n",
    "    title = row['title']\n",
    "    content = row['content']\n",
    "    label = row['label']\n",
    "    preprocess_text(title, content, sentences, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "文章分词: 快速 下跌 短时 跌破 美元 现报 美元 日内 涨幅 提醒\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 显示 短线 刚刚 突破 美元 关口 现报 美元 今日 涨幅 提醒\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: Fundstrat Global Advisors 研究 负责人 Tom Lee 近日 发推 表示 熊市 终于 结束 最近 一次 令人不安 下跌 急速 降至 美元 那次 随后 飙升 美元 加密 货币 冬天 已经 过去\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 分析 未来 几天 可能 回落 美元 第一季度 引领 市场 走高 LTC 显示 疲软 迹象 中旬 月底 LTC 几乎 走势 相同 多头 空头 比率 以来 首次 跌至 以下 表明 看跌 情绪 日益加剧 价格 回调 看起来 可能 价格 借助 上升 移动 平均线 目前 美元 反弹 下跌 美元 情况 将会 减弱\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 显示 持续 快速 上涨 高涨 美元 现稍 回落 现报 美元 今日 涨幅 提醒 APP 添加 自选 快人 一步 把握 投资 先机\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 早上 截至 小时 资金 净流入 排名 前三为 BNB 万美元 NCC 万美元 TUSD 万美元 资金 流出 排名 前三为 亿美元 亿美元 EOS 万美元 资金 流向 上币 资金 流向\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 持续 美元 附近 震荡 高涨 美元 最低 跌至 美元 主流 数字 货币 涨跌 各异 美元 24h 跌幅 全球 数字 货币 市场 总价值 亿美元 24h 成交量 亿美元 全球 均价 美元 三大 主流 交易所 现报 美元 现报 美元 币安现 美元 主流 数字 货币 表现 如下 暂报 美元 XRP 暂报 美元 BCH 暂报 美元 LTC 暂报 美元 ETC 暂报 美元 EOS 暂报 美元 小时 市值 排名 前百 币种 涨幅 前三为 LOOM DAC FT 跌幅 前三为 IOST RLC XZC 概念 板块 涨幅 前三为 平台 人工智能 区块 服务 板块 跌幅 前三为 共享 经济 合约 工具 电商 概念 以上 涨跌幅 24h 计算\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 短时 持续 下跌 跌破 美元 现报 美元 跌幅 提醒\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 据币安 显示 持续 上涨 现已 突破 美元 币安现 美元 涨幅\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 显示 刚刚 小幅 上升 突破 美元 现报 美元 今日 涨幅 提醒\n",
      "文章标签： 正面\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(sentences)\n",
    "for sentence in sentences[:10]:\n",
    "    print(\"-------\")\n",
    "    print(\"文章分词:\", sentence[0])\n",
    "    print(\"文章标签：\", sentence[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 抽取词向量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 抽取特征， 定义词袋模型\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vec = CountVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    ngram_range=(1,4),  # use ngrams of size 1 and 2\n",
    "    max_features=1500,  # keep the most common 1000 ngrams\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['负面', '中性', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '负面', '正面', '负面', '负面', '正面', '正面', '正面', '正面', '负面', '中性', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '中性', '正面', '正面', '正面', '负面', '正面', '正面', '负面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '负面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '负面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '负面', '负面', '正面', '负面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '负面', '负面', '负面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '中性', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '负面', '正面', '负面', '正面', '正面', '负面', '正面', '正面', '中性', '正面', '中性', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '负面', '正面', '负面', '正面', '正面', '负面', '正面', '正面', '正面', '负面', '正面', '负面', '负面', '负面', '正面', '负面', '正面', '中性', '正面', '负面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '负面', '负面', '正面', '正面', '正面', '正面', '中性', '负面', '负面', '正面', '负面', '正面', '中性', '正面', '负面', '负面', '负面', '正面', '正面', '中性', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '负面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '正面', '中性', '正面', '负面', '正面', '正面', '负面', '负面', '正面', '负面', '负面', '正面', '正面', '负面', '正面', '负面', '正面']\n"
     ]
    }
   ],
   "source": [
    "# 2. 语料切分\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.35, random_state=1256)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1500, min_df=1,\n",
       "        ngram_range=(1, 4), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 1200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 把训练数据转为词袋模型\n",
    "vec.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.算法建模与模型训练 （贝叶斯）\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# classifier = MultinomialNB()\n",
    "# classifier.fit(vec.transform(x_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 评估结果 AUC值\n",
    "# print(classifier.score(vec.transform(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM模型评价，训练集正确率 1.0\n",
      "SVM模型评价，测试集正确率 0.828571428571\n"
     ]
    }
   ],
   "source": [
    "# 4.算法建模与模型训练 （SVM）\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# svm = SVC(kernel='linear')\n",
    "svm = SVC(C=1.0,kernel='linear',gamma='auto')\n",
    "svm.fit(vec.transform(x_train), y_train)\n",
    "\n",
    "print(\"SVM模型评价，训练集正确率\",svm.score(vec.transform(x_train), y_train))\n",
    "print(\"SVM模型评价，测试集正确率\",svm.score(vec.transform(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目前准确率在测试集上为80%左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经网络模型评价，训练集正确率 1.0\n",
      "神经网络模型评价, 测试集正确率: 0.845714285714\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neural_network as sk_nn\n",
    "model = sk_nn.MLPClassifier(activation='tanh',solver='adam',alpha=0.0001,learning_rate='adaptive',learning_rate_init=0.001,max_iter=200)\n",
    "model.fit(vec.transform(x_train),y_train)\n",
    "\n",
    "print(\"神经网络模型评价，训练集正确率\", model.score(vec.transform(x_train), y_train))\n",
    "\n",
    "acc=model.score(vec.transform(x_test),y_test) #根据给定数据与标签返回正确率的均值\n",
    "print('神经网络模型评价, 测试集正确率:',acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
