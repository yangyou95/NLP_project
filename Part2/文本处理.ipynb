{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import jieba.analyse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 加载停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\百度停用词表.txt\"\n",
    "# stop_words_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\stopwords-master\\\\哈工大停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_projects/resources/stopwords-master/哈工大停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_projects/resources/stopwords-master/中文停用词表.txt\"\n",
    "\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/中文停用词表.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/百度停用词表.txt\"\n",
    "stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/modified_stopwords.txt\"\n",
    "# stop_words_path = \"/home/yang/PycharmProjects/NLP_project/resources/stopwords-master/四川大学机器智能实验室停用词库.txt\"\n",
    "\n",
    "stop_words = pd.read_csv(stop_words_path,index_col=False,quoting=3,sep=\"\\t\",names=['stopword'], encoding='utf-8')\n",
    "stop_words = stop_words['stopword'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = \"C:\\\\Users\\\\Name\\\\PycharmProjects\\\\NLP_project\\\\resources\\\\面试-训练测试集.xlsx\"\n",
    "# data_path = \"/home/yang/PycharmProjects/NLP_projects/resources/面试-训练测试集.xlsx\"\n",
    "data_path = \"/home/yang/PycharmProjects/NLP_project/resources/面试-训练测试集.xlsx\"\n",
    "data = pd.read_excel(data_path)\n",
    "\n",
    "# title_data = data['title']\n",
    "# content_data = data['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.定义文本预处理函数\n",
    "\n",
    "* 去停用词，分词\n",
    "* 参数 titles, contents, sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def is_percents(s):\n",
    "    s = str(s)\n",
    "    if s.count('.') ==1:\n",
    "        left = s.split('.')[0]\n",
    "        right = s.split('.')[1]\n",
    "        right = right.split('%')[0]\n",
    "        if right.isdigit():\n",
    "            if left.count('-')==1 and left.startswith('-'):\n",
    "                num = left.split['-'][-1]\n",
    "                if num.isdigit():\n",
    "                    return True\n",
    "            elif left.isdigit():\n",
    "                return True\n",
    "            \n",
    "    elif s.count(\".\") != 1:\n",
    "        left = s.split('%')[0]\n",
    "        if left.isdigit():\n",
    "            return True\n",
    "               \n",
    "    return False\n",
    "\n",
    "def is_all_chinese(strs):\n",
    "    for _char in strs:\n",
    "        if not '\\u4e00' <= _char <= '\\u9fa5':\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def preprocess_text(title, content, sentences, label):\n",
    "    \n",
    "#     处理标题\n",
    "    title_info = jieba.lcut(title)\n",
    "\n",
    "    title_info = [v for v in title_info if not str(v).isdigit()]#去数字\n",
    "    title_info = list(filter(lambda x:x.strip(), title_info))   #去左右空格\n",
    "    \n",
    "\n",
    "    title_info = list(filter(lambda x:len(x)>1, title_info)) #长度为1的字符\n",
    "    title_info = list(filter(lambda x:x not in stop_words, title_info)) #去掉停用词\n",
    "    \n",
    "#     print(\"标题信息是：\" ,title_info)\n",
    "#     sentences.append(segs)\n",
    "#     sentences.append((\" \".join(segs), label))# 打标签\n",
    "            \n",
    "#     处理文章内容        \n",
    "    segs=jieba.lcut(content)\n",
    "    segs = [v for v in segs if not str(v).isdigit()]#去数字\n",
    "    segs = [v for v in segs if not is_float(v)] #去小数\n",
    "    segs = [v for v in segs if not is_percents(v)] #去百分数\n",
    "\n",
    "    segs = list(filter(lambda x:x.strip(), segs))   #去左右空格\n",
    "    segs = list(filter(lambda x:len(x)>1, segs)) #长度为1的字符\n",
    "    segs = list(filter(lambda x:x not in stop_words, segs)) #去掉停用词\n",
    "    \n",
    "    \n",
    "#     print(\"内容信息是:\", segs)\n",
    "    segs = title_info + segs\n",
    "    \n",
    "    segs = [v for v in segs if is_all_chinese(str(v))] #去字母词\n",
    "    \n",
    "    \n",
    "    sentences.append((\" \".join(segs), label))# 打标签\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 文本预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "#     print(row['title'], row['content'])\n",
    "    title = row['title']\n",
    "    content = row['content']\n",
    "    label = row['label']\n",
    "    preprocess_text(title, content, sentences, label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------\n",
      "文章分词: 赵东 交易所 周线 放量 现在 反弹 不是 牛市 创始人 赵东 发微 博称 激动 交易所 周线 放量 现在 反弹 不是 牛市 牛会来 不是 现在 耐心\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 小幅 回调 美元 附近 宽幅 震荡 昨日 高涨 美元 目前 小幅 回调 主流 多数 小幅 回调 美元 跌幅 全球 数字 货币 市场 总价值 亿美元 成交量 亿美元 全球 均价 美元 三大 主流 交易所 现报 美元 现报 美元 币安现 美元 主流 数字 货币 表现 如下 暂报 美元 暂报 美元 暂报 美元 暂报 美元 暂报 美元 暂报 美元 小时 市值 排名 前百 币种 涨幅 前三为 跌幅 前三为 概念 板块 涨幅 前三为 技术 合约 工具 跨链 跌幅 前三为 人工智能 身份验证 联网 以上 涨跌幅 计算\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 短时 跌破 美元 刚刚 快速 下跌 短时 跌破 美元 最低 跌至 美元 略有 回升 现报 美元 今日 跌幅 提醒\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 过去 小时 推特 讨论 排名 第一 排名 三位 数据 显示 过去 小时 推特 讨论 排行 讨论 排名 第一 排名 第二位 排名 第三位 讨论 排名 四至 十位 分别\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 分析 美元 均线 支撑 有效 分析 未来 几天 可能 回落 美元 第一季度 引领 市场 走高 显示 疲软 迹象 中旬 月底 几乎 走势 相同 多头 空头 比率 以来 首次 跌至 以下 表明 看跌 情绪 日益加剧 价格 回调 看起来 可能 价格 借助 上升 移动 平均线 目前 美元 反弹 下跌 美元 情况 将会 减弱\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 分析 期货 多空 实力 反转 市场 情绪 逐渐 冷静 数据分析 显示 截止 点整 价格 收益 回报率 环比 昨日 跌幅 指数 处于 正常 区间 期货 方面 总多 单量 总空 单量 相较 此前 情况 市场 看好 情绪 已然 冷静 空头 势力 逐渐 攀升\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 过去 小时 推特 讨论 排名 第一 排名 三位 数据 显示 过去 小时 推特 讨论 排行 讨论 排名 第一 排名 第二位 排名 第三位 讨论 排名 四至 十位 分别\n",
      "文章标签： 中性\n",
      "-------\n",
      "文章分词: 链上 出现 价值 万美元 大额 转账 监测 北京 链上 出现 大额 转账 钱包 地址 地址 转账 价值 万美元\n",
      "文章标签： 正面\n",
      "-------\n",
      "文章分词: 主流 普跌 主流 币种 短时 持续 下跌 现报 美元 跌幅 现报 美元 跌幅 现报 美元 跌幅 主流 普跌 提醒\n",
      "文章标签： 负面\n",
      "-------\n",
      "文章分词: 短时 再次 跌破 美元 短时 持续 下跌 跌破 美元 现报 美元 跌幅 提醒\n",
      "文章标签： 负面\n"
     ]
    }
   ],
   "source": [
    "# random.shuffle(sentences)\n",
    "for sentence in sentences[:10]:\n",
    "    print(\"-------\")\n",
    "    print(\"文章分词:\", sentence[0])\n",
    "    print(\"文章标签：\", sentence[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 抽取词向量特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 抽取特征， 定义词袋模型\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# vec = CountVectorizer(\n",
    "#     analyzer='word', # tokenise by character ngrams\n",
    "#     ngram_range=(1,4),  # use ngrams of size 1 and 2\n",
    "#     max_features=1000,  # keep the most common 1000 ngrams\n",
    "# )\n",
    "\n",
    "vec = TfidfVectorizer(\n",
    "    analyzer='word', # tokenise by character ngrams\n",
    "    ngram_range=(1,3),  # use ngrams of size 1 and 2\n",
    "    max_features= None,  # keep the most common 1000 ngrams\n",
    "    use_idf=1,smooth_idf=1,sublinear_tf=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 语料切分\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x, y = zip(*sentences)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y,test_size=0.3, random_state=1256)\n",
    "# print(x_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=1, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=1, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=1, vocabulary=None)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. 把训练数据转为词袋模型\n",
    "vec.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "多项贝叶斯模型评价，训练集正确率: 0.9054441260744985\n",
      "多项贝叶斯模型评价，测试集正确率: 0.8533333333333334\n"
     ]
    }
   ],
   "source": [
    "# 4.算法建模与模型训练 （贝叶斯）\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(vec.transform(x_train), y_train)\n",
    "# 5. 评估结果 AUC值\n",
    "print(\"多项贝叶斯模型评价，训练集正确率:\",classifier.score(vec.transform(x_train), y_train))\n",
    "print(\"多项贝叶斯模型评价，测试集正确率:\",classifier.score(vec.transform(x_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM模型评价，训练集正确率 0.9684813753581661\n",
      "SVM模型评价，测试集正确率 0.9133333333333333\n"
     ]
    }
   ],
   "source": [
    "# 4.算法建模与模型训练 （SVM）\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "# svm = SVC(kernel='linear')\n",
    "svm = SVC(C=1.0,kernel='linear',gamma='auto')\n",
    "svm.fit(vec.transform(x_train), y_train)\n",
    "\n",
    "print(\"SVM模型评价，训练集正确率\",svm.score(vec.transform(x_train), y_train))\n",
    "print(\"SVM模型评价，测试集正确率\",svm.score(vec.transform(x_test), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目前准确率在测试集上为92%左右"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经网络模型评价，训练集正确率 0.9856733524355301\n",
      "神经网络模型评价, 测试集正确率: 0.92\n"
     ]
    }
   ],
   "source": [
    "import sklearn.neural_network as sk_nn\n",
    "model = sk_nn.MLPClassifier(activation='tanh',solver='sgd',alpha=0.0001,learning_rate='adaptive',learning_rate_init=0.01,max_iter=1000)\n",
    "model.fit(vec.transform(x_train),y_train)\n",
    "\n",
    "print(\"神经网络模型评价，训练集正确率\", model.score(vec.transform(x_train), y_train))\n",
    "\n",
    "acc=model.score(vec.transform(x_test),y_test) #根据给定数据与标签返回正确率的均值\n",
    "print('神经网络模型评价, 测试集正确率:',acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<script>\n",
       "    require.config({\n",
       "        paths: {\n",
       "            'echarts':'https://assets.pyecharts.org/assets/echarts.min'\n",
       "        }\n",
       "    });\n",
       "</script>\n",
       "\n",
       "        <div id=\"d40b775abc5a49da9e93550a5b5dd998\" style=\"width:900px; height:500px;\"></div>\n",
       "\n",
       "<script>\n",
       "        require(['echarts'], function(echarts) {\n",
       "                var chart_d40b775abc5a49da9e93550a5b5dd998 = echarts.init(\n",
       "                    document.getElementById('d40b775abc5a49da9e93550a5b5dd998'), 'white', {renderer: 'canvas'});\n",
       "                var option_d40b775abc5a49da9e93550a5b5dd998 = {\n",
       "    \"animation\": true,\n",
       "    \"animationThreshold\": 2000,\n",
       "    \"animationDuration\": 1000,\n",
       "    \"animationEasing\": \"cubicOut\",\n",
       "    \"animationDelay\": 0,\n",
       "    \"animationDurationUpdate\": 300,\n",
       "    \"animationEasingUpdate\": \"cubicOut\",\n",
       "    \"animationDelayUpdate\": 0,\n",
       "    \"color\": [\n",
       "        \"#c23531\",\n",
       "        \"#2f4554\",\n",
       "        \"#61a0a8\",\n",
       "        \"#d48265\",\n",
       "        \"#749f83\",\n",
       "        \"#ca8622\",\n",
       "        \"#bda29a\",\n",
       "        \"#6e7074\",\n",
       "        \"#546570\",\n",
       "        \"#c4ccd3\",\n",
       "        \"#f05b72\",\n",
       "        \"#ef5b9c\",\n",
       "        \"#f47920\",\n",
       "        \"#905a3d\",\n",
       "        \"#fab27b\",\n",
       "        \"#2a5caa\",\n",
       "        \"#444693\",\n",
       "        \"#726930\",\n",
       "        \"#b2d235\",\n",
       "        \"#6d8346\",\n",
       "        \"#ac6767\",\n",
       "        \"#1d953f\",\n",
       "        \"#6950a1\",\n",
       "        \"#918597\"\n",
       "    ],\n",
       "    \"series\": [\n",
       "        {\n",
       "            \"type\": \"bar\",\n",
       "            \"name\": \"\\u5546\\u5bb6A\",\n",
       "            \"data\": [\n",
       "                5,\n",
       "                20,\n",
       "                36,\n",
       "                10,\n",
       "                75,\n",
       "                90\n",
       "            ],\n",
       "            \"barCategoryGap\": \"20%\",\n",
       "            \"label\": {\n",
       "                \"show\": true,\n",
       "                \"position\": \"top\",\n",
       "                \"margin\": 8\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"legend\": [\n",
       "        {\n",
       "            \"data\": [\n",
       "                \"\\u5546\\u5bb6A\"\n",
       "            ],\n",
       "            \"selected\": {\n",
       "                \"\\u5546\\u5bb6A\": true\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"tooltip\": {\n",
       "        \"show\": true,\n",
       "        \"trigger\": \"item\",\n",
       "        \"triggerOn\": \"mousemove|click\",\n",
       "        \"axisPointer\": {\n",
       "            \"type\": \"line\"\n",
       "        },\n",
       "        \"textStyle\": {\n",
       "            \"fontSize\": 14\n",
       "        },\n",
       "        \"borderWidth\": 0\n",
       "    },\n",
       "    \"xAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            },\n",
       "            \"data\": [\n",
       "                \"\\u886c\\u886b\",\n",
       "                \"\\u7f8a\\u6bdb\\u886b\",\n",
       "                \"\\u96ea\\u7eba\\u886b\",\n",
       "                \"\\u88e4\\u5b50\",\n",
       "                \"\\u9ad8\\u8ddf\\u978b\",\n",
       "                \"\\u889c\\u5b50\"\n",
       "            ]\n",
       "        }\n",
       "    ],\n",
       "    \"yAxis\": [\n",
       "        {\n",
       "            \"show\": true,\n",
       "            \"scale\": false,\n",
       "            \"nameLocation\": \"end\",\n",
       "            \"nameGap\": 15,\n",
       "            \"gridIndex\": 0,\n",
       "            \"inverse\": false,\n",
       "            \"offset\": 0,\n",
       "            \"splitNumber\": 5,\n",
       "            \"minInterval\": 0,\n",
       "            \"splitLine\": {\n",
       "                \"show\": false,\n",
       "                \"lineStyle\": {\n",
       "                    \"width\": 1,\n",
       "                    \"opacity\": 1,\n",
       "                    \"curveness\": 0,\n",
       "                    \"type\": \"solid\"\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    ]\n",
       "};\n",
       "                chart_d40b775abc5a49da9e93550a5b5dd998.setOption(option_d40b775abc5a49da9e93550a5b5dd998);\n",
       "        });\n",
       "    </script>\n"
      ],
      "text/plain": [
       "<pyecharts.render.display.HTML at 0x7f923a7d6710>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyecharts.charts import Bar\n",
    "\n",
    "bar = Bar()\n",
    "bar.add_xaxis([\"衬衫\", \"羊毛衫\", \"雪纺衫\", \"裤子\", \"高跟鞋\", \"袜子\"])\n",
    "bar.add_yaxis(\"商家A\", [5, 20, 36, 10, 75, 90])\n",
    "# render 会生成本地 HTML 文件，默认会在当前目录生成 render.html 文件\n",
    "# 也可以传入路径参数，如 bar.render(\"mycharts.html\")\n",
    "bar.render_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 检验模型　https://blog.csdn.net/hao5335156/article/details/81268731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
